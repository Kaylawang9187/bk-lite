{
  "plugin": "GreenPlum-Exporter",
  "plugin_desc": "GreenPlum-Exporter collects GreenPlum uptime, operation counts, transaction commits/rollbacks, and wait times in real-time, aiding in health checks and performance tuning.。",
  "name": "GreenPlum",
  "icon": "greenplum",
  "type": "Database",
  "metrics": [
     {
      "metric_group": "Base",
      "name": "greenplum_up",
      "query": "greenplum_up_gauge{__$labels__}",
      "display_name": "Monitoring Plugin Operating Status",
      "instance_id_keys": ["instance_id"],
      "data_type": "Enum",
      "unit": "[{\"id\":0,\"name\":\"Unavailable\",\"description\":\"Exporter无法连接集群\",\"color\":\"#ff4d4f\"},{\"id\":1,\"name\":\"Available\",\"description\":\"Exporter正常运行\",\"color\":\"#52c41a\"}]",
      "dimensions": [],
      "description": "This metric is used to monitor the overall accessibility of the database cluster, and the binary status value is used to visually reflect whether the service is online or not. If the return value is 1, the monitoring agent can successfully connect to the database cluster and all core service ports respond normally. A return value of 0 indicates a failed connection or unresponsive critical service, and it is often necessary to immediately check the network configuration, firewall rules, and the health status of the database master process. This metric is the most basic and important health indicator on the O&M dashboard, and any non-1 status should trigger an alarm and start the troubleshooting process.."
    },
    {
      "metric_group": "Base",
      "name": "greenplum_cluster_state",
      "query": "greenplum_cluster_state_gauge{__$labels__}",
      "display_name": "Cluster status",
      "instance_id_keys": ["instance_id"],
      "data_type": "Enum",
      "unit": "[{\"id\":0,\"name\":\"Stopped\",\"description\":\"集群服务停止\",\"color\":\"#ff4d4f\"},{\"id\":1,\"name\":\"Running\",\"description\":\"集群正常服务\",\"color\":\"#52c41a\"},{\"id\":2,\"name\":\"Recovering\",\"description\":\"集群正在启动/恢复\",\"color\":\"#faad14\"}]",
      "dimensions": [
        {"name": "version", "description": "集群版本"},
        {"name": "master", "description": "主节点信息"}
      ],
      "description": "This metric is used to monitor the overall accessibility of the database cluster, and the binary status value is used to visually reflect whether the service is online or not. If the return value is 1, the monitoring agent can successfully connect to the database cluster and all core service ports respond normally. A return value of 0 indicates a failed connection or unresponsive critical service, and it is often necessary to immediately check the network configuration, firewall rules, and the health status of the database master process. This metric is the most basic and important health indicator on the O&M dashboard, and any non-1 status should trigger an alarm and start the troubleshooting process."
    },

   {
      "metric_group": "Cluster",
      "name": "greenplum_cluster_uptime",
      "query": "greenplum_cluster_uptime_gauge{__$labels__}/3600",
      "display_name": "Cluster uptime",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "h",
      "dimensions": [],
      "description": "This cumulative value in seconds records exactly how long the cluster has been running continuously since it was last started. O&M teams can use this metric to evaluate system stability, and long-running clusters (usually more than 30 days) may experience memory fragmentation or resource leakage. When analyzing performance issues, this metric can help determine if a planned restart is needed. At the same time, it is also a key basic data for calculating the availability of the system."
    },
    {
      "metric_group": "Cluster",
      "name": "greenplum_cluster_sync",
      "query": "greenplum_cluster_sync_gauge{__$labels__}",
      "display_name": "Cluster sync status",
      "instance_id_keys": ["instance_id"],
      "data_type": "Enum",
      "unit": "[{\"id\":0,\"name\":\"Not Synced\",\"description\":\"主备数据不同步\",\"color\":\"#ff4d4f\"},{\"id\":1,\"name\":\"Syncing\",\"description\":\"正在同步\",\"color\":\"#faad14\"},{\"id\":2,\"name\":\"Synced\",\"description\":\"数据完全一致\",\"color\":\"#52c41a\"}]",
      "dimensions": [],
      "description": "This metric monitors the progress of data synchronization between the primary node and the standby node, and uses a three-state identifier: 1 is returned in the full synchronization state, which is a necessary condition for normal business operation. If a value of 0 is displayed, there is a difference in the primary/standby data, which may be caused by network interruption or abnormal replication process. The transition status in synchronization is marked as 2. In scenarios that require high data consistency, such as finance, real-time monitoring of this indicator is required, and any non-1 status should be of great concern."
    },
    {
      "metric_group": "Cluster",
      "name": "greenplum_cluster_max_connections",
      "query": "greenplum_cluster_max_connections_gauge{__$labels__}",
      "display_name": "Max connections",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [],
      "description": "This number represents the maximum number of concurrent connections allowed by the database engine configuration and is an important capacity planning parameter. When the number of active connections approaches this threshold, new connection requests will be rejected, resulting in an error on the application side. This parameter is usually set in the postgresql.conf configuration file, and O&M personnel should adjust it reasonably according to the peak service demand and reserve about 20% of the buffer space. Monitoring this metric can help predict capacity bottlenecks."
    },
    {
      "metric_group": "Cluster",
      "name": "greenplum_cluster_total_connections",
      "query": "greenplum_node_database_table_total_count_gauge{__$labels__}",
      "display_name": "Current connections",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [],
      "description": "Real-time statistics on the total number of connections currently established to the database, including active connections that are executing queries and idle connections in the keepalive connection pool. This metric directly reflects the overall load pressure of the DB instance, and should normally fluctuate periodically, which coincides with peak business hours. If you find that the value is persistently close to the maximum number of connections, you may need to optimize the connection pool configuration or expand the database resources."
    },
    {
      "metric_group": "Cluster",
      "name": "greenplum_cluster_idle_connections",
      "query": "greenplum_cluster_idle_connections_gauge{__$labels__}",
      "display_name": "Idle connections",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [],
      "description": "Specifically counts the number of connections in a connection pool that are not currently in use. The right amount of idle connections is good for responding quickly to bursty requests, but too many idle connections (especially more than 50% of the total number of connections) means wasted resources. Ideally, the number of idle connections fluctuates naturally with the high and low peaks of the service, and if it remains high for a long time, it is recommended to adjust the minimum and maximum number of connections in the connection pool."
    },
    {
      "metric_group": "Cluster",
      "name": "greenplum_cluster_active_connections",
      "query": "greenplum_cluster_active_connections_gauge{__$labels__}",
      "display_name": "Active connections",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [],
      "description": "Real-time display of the number of connections that are executing SQL queries is the most direct indicator of database load. This value fluctuates in real time with the number of business queries, and needs to be comprehensively analyzed based on metrics such as CPU and memory. If the value remains high, it may cause a delay in queuing queuing, and you need to analyze slow queries or consider increasing computing resources. In the OLTP system, this metric is usually highly consistent with the business activity curve."
    },
    {
      "metric_group": "Cluster",
      "name": "greenplum_cluster_running_connections",
      "query": "greenplum_cluster_running_connections_gauge{__$labels__}",
      "display_name": "Running connections",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [],
      "description": "This metric counts the total number of connections in the Running state, including user queries and background tasks. It is a more comprehensive reflection of the actual workload of the database than the number of active connections. It is important to note that some maintenance tasks, such as VACUUM, also occupy the uptime connection and should be distinguished when analyzing performance issues. An unusually high spike can indicate a large number of concurrent requests or long running transactions."
    },
    {
      "metric_group": "Cluster",
      "name": "greenplum_cluster_waiting_connections",
      "query": "greenplum_cluster_waiting_connections_gauge{__$labels__}",
      "display_name": "Waiting connections",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [],
      "description": "Recording the number of connections that are waiting due to resource contention is a key metric for identifying performance bottlenecks. Common waiting causes include lock conflicts, insufficient I/O bandwidth, and CPU saturation. If the value of this metric is greater than 0 for a long time, it indicates that the system has a resource contention problem, which needs to be further located in combination with the analysis of waiting events. In OLAP scenarios, this metric is particularly important for optimizing concurrent query strategies."
    },


    {
      "metric_group": "Node",
      "name": "greenplum_node_segment_status",
      "query": "greenplum_node_segment_status_gauge{__$labels__}",
      "display_name": "Segment status",
      "instance_id_keys": ["instance_id"],
      "data_type": "Enum",
      "unit": "[{\"id\":0,\"name\":\"Critical\",\"description\":\"节点不可用\",\"color\":\"#ff4d4f\"},{\"id\":1,\"name\":\"Healthy\",\"description\":\"节点正常运行\",\"color\":\"#52c41a\"},{\"id\":2,\"name\":\"Warning\",\"description\":\"性能降级但可用\",\"color\":\"#faad14\"}]",
      "dimensions": [
        {"name": "hostname", "description": "节点主机名"},
        {"name": "address", "description": "IP地址"},
        {"name": "dbid", "description": "数据库ID"},
        {"name": "content", "description": "Segment内容ID"},
        {"name": "preferred_role", "description": "首选角色"},
        {"name": "port", "description": "服务端口"}
      ],
      "description": "Monitor the health status of each data node (segment) using standard three-state encoding: 1 indicates that the node is completely healthy and can read and write normally; 0 indicates that the node is completely faulty and requires manual intervention. 2 indicates that the node is in a degraded state (e.g., read-only). In a distributed architecture, a single node failure may not immediately affect cluster availability, but it can degrade overall performance, so all node states need to be monitored in real time."
    },
    {
      "metric_group": "Node",
      "name": "greenplum_node_segment_role",
      "query": "greenplum_node_segment_role_gauge{__$labels__}",
      "display_name": "Segment role",
      "instance_id_keys": ["instance_id"],
      "data_type": "Enum",
      "unit": "[{\"id\":0,\"name\":\"Standby\",\"description\":\"备节点\",\"color\":\"#d3adf7\"},{\"id\":1,\"name\":\"Primary\",\"description\":\"主节点\",\"color\":\"#52c41a\"},{\"id\":2,\"name\":\"Mirror\",\"description\":\"镜像节点\",\"color\":\"#91d5ff\"}]",
      "dimensions": [
        {"name": "hostname", "description": "节点主机名"},
        {"name": "address", "description": "IP地址"},
        {"name": "dbid", "description": "数据库ID"},
        {"name": "content", "description": "Segment内容ID"},
        {"name": "preferred_role", "description": "首选角色"},
        {"name": "port", "description": "服务端口"}
      ],
      "description": "Identifies the role attributes of each segment node in a distributed architecture. The primary role node (typically labeled 1) is responsible for handling writes and queries, and the secondary role node (labeled 0) provides read and failover capabilities. Some deployments may have special roles (for example, 2 for mirror nodes). Understanding node role distribution is critical to balancing read and write loads and planning for high availability strategies."
    },
    {
      "metric_group": "Node",
      "name": "greenplum_node_segment_mode",
      "query": "greenplum_node_segment_mode_gauge{__$labels__}",
      "display_name": "Segment mode",
      "instance_id_keys": ["instance_id"],
      "data_type": "Enum",
      "unit": "[{\"id\":0,\"name\":\"Maintenance\",\"description\":\"维护模式\",\"color\":\"#ffa940\"},{\"id\":1,\"name\":\"Production\",\"description\":\"生产模式\",\"color\":\"#52c41a\"},{\"id\":2,\"name\":\"Development\",\"description\":\"开发模式\",\"color\":\"#9254de\"}]",
      "dimensions": [
        {"name": "hostname", "description": "节点主机名"},
        {"name": "address", "description": "IP地址"},
        {"name": "dbid", "description": "数据库ID"},
        {"name": "content", "description": "Segment内容ID"},
        {"name": "preferred_role", "description": "首选角色"},
        {"name": "port", "description": "服务端口"}
      ],
      "description": "Define the type of running environment for the segment node, the production environment is usually set to 1, and all optimizations and limits will be enabled at this time. Maintenance mode (0) is used for system upgrades or repairs, which will limit some functions; DevTest mode (2) may turn off security checks for certain production environments. Incorrect environment configurations can lead to performance issues or security concerns that require special attention when deploying."
    },
    {
      "metric_group": "Node",
      "name": "greenplum_node_segment_disk_free_gb_size",
      "query": "greenplum_node_segment_disk_free_gb_size_gauge{__$labels__}",
      "display_name": "Free disk space",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "decgbytes",
      "dimensions": [
        {"name": "hostname", "description": "节点主机名"}
      ],
      "description": "Accurately displays the GB of available disk space for each segment node, which is the core metric of capacity management. If the remaining space is less than 10%, database operations may be blocked, and you are advised to set hierarchical alarms (for example, 20% warning and 10% severe). When analyzing this metric, it is necessary to predict the remaining available time in combination with the data growth trend, especially in scenarios with frequent ETL tasks."
    },



   {
      "metric_group": "Connection",
      "name": "greenplum_cluster_total_connections_per_client",
      "query": "sum(greenplum_cluster_total_connections_per_client_gauge{__$labels__}) by (instance_id)",
      "display_name": "Total connections per client !",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [
        {"name": "client", "description": "客户端标识"}
      ],
      "description": "Collects statistics on the number of connections by client IP address or application ID to analyze the distribution of connection sources. This metric is especially useful for identifying unusual connections, such as a client creating too many connections. In a microservice architecture, a healthy distribution of connections should be proportional to the number of nodes in the business application, and a significant deviation may indicate a connection leak or load balancing failure."
    },
    {
      "metric_group": "Connection",
      "name": "greenplum_cluster_idle_connections_per_client",
      "query": "greenplum_cluster_idle_connections_per_client_gauge{__$labels__}",
      "display_name": "Idle connections per client !",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [
        {"name": "client", "description": "客户端标识"}
      ],
      "description": "This metric counts the number of unused connections by client dimension to help identify the connection resource usage of a specific application or service. By analyzing the distribution of idle connections among different clients, you can find application instances with improper connection pool configuration or connection leaks. For example, if a microservice maintains a large number of idle connections for a long period of time, it may indicate that its connection pool maximum idle value is set too high. We recommend that you monitor the client by group based on the client identifier (such as IP address or application name) and set threshold alarms for outliers."
    },
    {
      "metric_group": "Connection",
      "name": "greenplum_cluster_active_connections_per_client",
      "query": "greenplum_cluster_active_connections_per_client_gauge{__$labels__}",
      "display_name": "Active connections per client !",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [
        {"name": "client", "description": "客户端标识"}
      ],
      "description": "Statistics on the number of connections that are being queried by client source directly reflect the real-time load pressure of each business system. This metric is especially important for multi-tenant environments to identify the source of the load burst. When the number of active connections to a particular client consistently exceeds its quota, query optimization or resource isolation may be required. During the analysis, we recommend that you use the SQL query type and duration metrics to locate the specific cause of the high load."
    },
    {
      "metric_group": "Connection",
      "name": "greenplum_cluster_total_online_user_count",
      "query": "greenplum_cluster_total_online_user_count_gauge{__$labels__}",
      "display_name": "Online users",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [],
      "description": "Collects statistics on the number of unique users who successfully log in to the database using different authentication methods (such as password or LDAP). This metric includes both users who connect directly and those who connect through the app pool. Monitoring this metric can detect anomalous logon behavior, such as a sudden increase in after-hours, and is an important basis for evaluating license usage. It is recommended to correlate and analyze user activity logs to identify long-term inactive accounts."
    },
    {
      "metric_group": "Connection",
      "name": "greenplum_cluster_total_client_count",
      "query": "greenplum_cluster_total_client_count_gauge{__$labels__}",
      "display_name": "Total clients",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [],
      "description": "Reflects the number of unique clients currently connected to the database (deduplicated by IP or application identity). In a microservices architecture, the number of healthy clients should match the number of application instances deployed. If you notice an abnormal increase in the number of clients, it may indicate unauthorized access or a misconfigured autoscaling policy. This metric is of great value for cybersecurity audits and capacity planning."
    },
    {
      "metric_group": "Connection",
      "name": "greenplum_cluster_total_connections_per_user",
      "query": "sum(greenplum_cluster_total_connections_per_user_gauge{__$labels__}) by (instance_id)",
      "display_name": "Total connections per user",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [
        {"name": "usename", "description": "用户名"}
      ],
      "description": "Collects the total number of connections made by database user name, including active and idle connections. This metric identifies users who consume the most connections, especially in a shared database environment. For example, a report user might be consuming too many connection resources, and you might need to consider connection throttling or query optimization. We recommend that you set a quota alert for key service users."
    },
    {
      "metric_group": "Connection",
      "name": "greenplum_cluster_idle_connections_per_user",
      "query": "greenplum_cluster_idle_connections_per_user_gauge{__$labels__}",
      "display_name": "Idle connections per user",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [
        {"name": "usename", "description": "用户名"}
      ],
      "description": "Collects the number of connections that are currently idle by user name. Combined with the analysis of the total number of user connections, you can evaluate the connection efficiency of each user. Some ORM frameworks may have too many idle connections by default, and this metric can be used to target applications that need to be optimized. When connection resources are tight, user connections that have been idle for a long time can be reclaimed first."
    },
    {
      "metric_group": "Connection",
      "name": "greenplum_cluster_active_connections_per_user",
      "query": "greenplum_cluster_active_connections_per_user_gauge{__$labels__}",
      "display_name": "Active connections per user",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [
        {"name": "usename", "description": "用户名"}
      ],
      "description": "Accurately displaying the number of query connections that are being executed by each database user is a key metric for identifying 'hot users'. If you find that the number of active connections for a particular user is abnormally high, you may want to check the queries submitted by a particular user for performance issues or evaluate whether read/write splitting is required. This metric is especially important for resource quota management in multitenant systems."
    },

   {
      "metric_group": "Other",
      "name": "greenplum_cluster_config_last_load_time_seconds",
      "query": "greenplum_cluster_config_last_load_time_seconds_gauge{__$labels__}/3600/24",
      "display_name": "Config last load time",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "d",
      "dimensions": [],
      "description": "Record the Unix timestamp (seconds precision) of the most recent successful load of the cluster configuration file. This metric change usually occurs after the parameter is adjusted or restarted, and can be used to verify whether the configuration change takes effect. In the configuration management system, you can compare this timestamp with the expected change time to ensure the timeliness of configuration synchronization. Not updating for a long time can indicate a risk of configuration drift."
    },
    {
      "metric_group": "Storage",
      "name": "greenplum_node_database_name_mb_size",
      "query": "greenplum_node_database_name_mb_size_gauge{__$labels__}",
      "display_name": "Database storage size",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "decmbytes",
      "dimensions": [
        {"name": "dbname", "description": "数据库名称"}
      ],
      "description": "ACCURATELY MEASURE THE PHYSICAL STORAGE SPACE (INCLUDING TABLES, INDEXES, TOAST DATA, ETC.) OCCUPIED BY A SINGLE DATABASE, MEASURED IN MEGABYTES. This metric is critical for capacity planning, especially for fast-growing business databases. It is advisable to analyze the growth trend by time series and predict the useful life of the remaining space. In a distributed environment, be aware that this value may differ from the actual disk usage depending on the data distribution strategy."
    },
    {
      "metric_group": "Storage",
      "name": "greenplum_node_database_table_total_count",
      "query": "sum(greenplum_node_database_table_total_count_gauge{__$labels__}) by (instance_id)",
      "display_name": "Total tables in database",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [
        {"name": "dbname", "description": "数据库名称"}
      ],
      "description": "Collects statistics on the total number of table objects (including user tables and system tables) in a specified database. Abnormal growth may indicate a temporary table or design flaw that has not been cleaned up. In metadata management, this metric can help assess database complexity, and a large number of tables (e.g., more than 10,000) can affect query planning performance. It is recommended that you archive or partition the history table on a regular basis."
    },
    {
      "metric_group": "Server",
      "name": "greenplum_server_locks_table_detail",
      "query": "greenplum_server_locks_table_detail_gauge{__$labels__}/1000/1000/1000",
      "display_name": "Table lock details",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [
        {"name": "pid", "description": "进程ID"},
        {"name": "datname", "description": "数据库名"},
        {"name": "usename", "description": "用户名"},
        {"name": "locktype", "description": "锁类型"},
        {"name": "mode", "description": "锁模式"},
        {"name": "application_name", "description": "应用名称"},
        {"name": "state", "description": "会话状态"},
        {"name": "lock_satus", "description": "锁状态"},
        {"name": "query", "description": "SQL语句"}
      ],
      "description": "Provides fine-grained table lock wait conditions, including lock modes (such as AccessShareLock/ExclusiveLock), holders, and waiter information. This metric is critical for diagnosing deadlocks and concurrency conflicts. When high-frequency lock waits are discovered, you may need to adjust the transaction isolation level or optimize the query pattern. We recommend that you set a lock waiting timeout alarm on key service tables."
    },
    {
      "metric_group": "Server",
      "name": "greenplum_server_database_hit_cache_percent_rate",
      "query": "greenplum_server_database_hit_cache_percent_rate_gauge{__$labels__}",
      "display_name": "Cache hit rate",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "percent",
      "dimensions": [],
      "description": "Shows the percentage of queries that are read from the shared buffer, ideally above 99%. A low hit rate indicates that the disk I/O is under high pressure and may need to be increased shared_buffers parameter values or the query working set may be optimized. When profiling, you should distinguish between global hit ratios and hit ratios for specific tables, and consider separate caching policies for hot tables. In OLAP scenarios, this metric is usually lower than that of OLTP systems."
    },
    {
      "metric_group": "Server",
      "name": "greenplum_server_database_transition_commit_percent_rate",
      "query": "greenplum_server_database_transition_commit_percent_rate_gauge{__$labels__}",
      "display_name": "Transaction commit rate",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "percent",
      "dimensions": [],
      "description": "Recording the percentage of successfully committed transactions out of the total number of transactions is a key metric for data consistency. Values below 99.9% may indicate constraint violations, deadlocks, or system failures. The cause of failure needs to be analyzed in conjunction with error logs, especially in distributed transaction scenarios. For the financial system, the indicator should be close to 100%, and any decline needs to be investigated immediately."
    },

    {
      "metric_group": "selfMonitor",
      "name": "greenplum_exporter_total_scraped",
      "query": "sum(greenplum_exporter_total_scraped_counter{__$labels__})by(instance_id)",
      "display_name": "Exporter total scrapes",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [],
      "description": "The total number of times the monitoring agent successfully collects metrics is recorded. By analyzing the change in the acquisition frequency, the stability of the monitoring system can be evaluated. A sudden drop in the number of ingestions can indicate a network issue or proxy failure. This metric is usually used in conjunction with error counting to calculate the success rate of collection. In large clusters, you need to pay attention to the impact of collection frequency on database performance."
    },
    {
      "metric_group": "selfMonitor",
      "name": "greenplum_exporter_total_error",
      "query": "sum(greenplum_exporter_total_error_counter{__$labels__})by(instance_id)",
      "display_name": "Exporter total errors",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "short",
      "dimensions": [],
      "description": "Collect statistics on various errors encountered during monitoring (such as connection timeout, permission denial, and resolution failure). A non-zero value indicates that the monitoring data may be missing or inaccurate. It is recommended to classify and collect statistics by error type, and prioritize high-frequency errors. This indicator is also an important basis for evaluating the reliability of the monitoring system, and the continuous increase in the number of errors requires timely intervention."
    },
    {
      "metric_group": "selfMonitor",
      "name": "greenplum_exporter_scrape_duration_second",
      "query": "greenplum_exporter_scrape_duration_second_gauge{__$labels__}",
      "display_name": "Exporter scrape duration",
      "instance_id_keys": ["instance_id"],
      "data_type": "Number",
      "unit": "s",
      "dimensions": [],
      "description": "Accurately measure the time (milliseconds) taken to collect each metric, reflecting the degree of impact of the monitoring agent on the database. Under normal circumstances, it should be completed within 1 second, but long acquisition (e.g., more than 5 seconds) may cause a delay in monitoring data. A sudden increase in this metric may indicate a slower database response or an increase in query complexity. During periods of high load, you may need to adjust the collection interval or simplify monitoring queries."
    }
  ]
}